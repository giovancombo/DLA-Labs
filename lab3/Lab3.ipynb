{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bdf4d12",
   "metadata": {},
   "source": [
    "***Deep Learning Applications 2023** course, held by Professor **Andrew David Bagdanov** - University of Florence, Italy*\n",
    "\n",
    "*Notebook and code created by **Giovanni Colombo** - Mat. 7092745*\n",
    "\n",
    "Check the dedicated [Repository on GitHub](https://github.com/giovancombo/DLA-Labs/tree/main/lab3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae2782-57ea-48f0-b948-b412d0076ffc",
   "metadata": {},
   "source": [
    "# Deep Learning Applications: Laboratory #3 - DRL\n",
    "\n",
    "In this laboratory session we will hack one of your colleague's (Francesco Fantechi, from Ingegneria Informatica) implementation of a navigation environment for Deep Reinforcement Learning. The setup is fairly simple:\n",
    "\n",
    "+ A simple 2D environment with a (limited) number of *obstacles* and a single *goal* is presented to the agent, which must learn how to navigate to the goal without hitting any obstacles.\n",
    "+ The agent *observes* the environment via a set of 16 rays cast uniformly which return the distance to the first obstacle encountered, as well as the distance and direction to the goal.\n",
    "+ The agent has three possible actions: `ROTATE LEFT`, `ROTATE RIGHT`, or `MOVE FORWARD`.\n",
    "\n",
    "For each step of an episode, the agent receives a reward of:\n",
    "+ -100 if hitting an obstacle (episode ends).\n",
    "+ -100 if one hundred steps are reached without hitting the goal.\n",
    "+ +100 if hitting the goal (episode ends)\n",
    "+ A small *positive* reward if the distance to the goal is *reduced*.\n",
    "+ A small *negative* reward if the distance to the goal is *increased*.\n",
    "\n",
    "In the file `main.py` you will find an implementation of **Deep Q-Learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5adad7-759b-4000-925b-701f41fe6e97",
   "metadata": {},
   "source": [
    "## Exercise 1: Testing the Environment\n",
    "\n",
    "The first thing to do is verify that the environment is working in your Anaconda virtual environment. I had a weird problem with Tensorboard and had to downgrade it using:\n",
    "\n",
    "    conda install -c conda-forge tensorboard=2.11.2\n",
    "    \n",
    "In any case, you should be able to run:\n",
    "\n",
    "    python main.py\n",
    "    \n",
    "from the repository root and it will run episodes using a pretrained agent. To train an agent from scratch, you must modify `main.py` setting `TRAIN = True` at the top. Then running `main.py` again will train an agent for 2000 episodes of training. To run the trained agent you will again have to modify `main.py` on line 225 to load the last saved checkpoint:\n",
    "\n",
    "    PATH = './checkpoints/last.pth'\n",
    "    \n",
    "and then run the script again (after setting `TRAIN = False` !).\n",
    "\n",
    "Make sure you can at run the demo agent and train one from scratch. If you don't have a GPU you can set the number of training episodes to a smaller number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TRAIN = True for training and then False for testing\n",
    "!python Navigation_Goal_Deep_Q_Learning/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac9092",
   "metadata": {},
   "source": [
    "Well, I guess I did it. The main script works. I let it train for 1000 episodes.\n",
    "\n",
    "Qualitatively, it's possible to see that the agents looks like it has not learned so well to find the goal. Many times, the agent hits the walls or obstables without even trying to change direction, even just after the spawn. Some other times, the agent finds its way to the goal, until it stops right in front of it and changes direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed9279-3a2f-4fcd-bf29-b105b2da8433",
   "metadata": {},
   "source": [
    "## Exercise 2: Stabilizing Q-Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feafbec",
   "metadata": {},
   "source": [
    "## Exercise 3: Going Deeper\n",
    "\n",
    "As usual, pick **AT LEAST ONE** of the following exercises to complete.\n",
    "\n",
    "### Exercise 3.1: Solving the environment with `REINFORCE`\n",
    "\n",
    "Use my (or even better, improve on my) implementation of `REINFORCE` to solve the environment.\n",
    "\n",
    "**Note**: There is a *design flaw* in the environment implementation that will lead to strange (by explainable) behavior in agents trained with `REINFORCE`. See if you can figure it out and fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "12742de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running reward: -0.9353093063354492\n",
      "Running reward: -1.3599613349380493\n",
      "Running reward: -1.774640257511406\n",
      "Running reward: -2.2050206725568566\n",
      "Running reward: -2.5085219173080864\n",
      "Running reward: -2.9942807756170535\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [703], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m policy \u001b[38;5;241m=\u001b[39m PolicyNet(env, \u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Train the agent.\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m running  \u001b[38;5;241m=\u001b[39m reinforce(policy, env, env_render, device\u001b[38;5;241m=\u001b[39mdevice, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, num_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     20\u001b[0m running \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reinforce(policy, env, env_render, device\u001b[38;5;241m=\u001b[39mdevice, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, num_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(running)\n",
      "File \u001b[1;32mc:\\Users\\giova\\__UNI\\Deep Learning Applications\\DLA-Labs\\lab3\\reinforce.py:85\u001b[0m, in \u001b[0;36mreinforce\u001b[1;34m(policy, env, env_render, gamma, lr, num_episodes, device)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m episode \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m:\n\u001b[0;32m     84\u001b[0m     policy\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 85\u001b[0m     (obs, _, _, _) \u001b[38;5;241m=\u001b[39m \u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_render\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     policy\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_rewards[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\giova\\__UNI\\Deep Learning Applications\\DLA-Labs\\lab3\\reinforce.py:44\u001b[0m, in \u001b[0;36mrun_episode\u001b[1;34m(env, policy, maxlen, device)\u001b[0m\n\u001b[0;32m     41\u001b[0m log_probs\u001b[38;5;241m.\u001b[39mappend(log_prob)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Advance the episode by executing the selected action.\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m (obs, reward, term, trunc, info) \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m rewards\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m term \u001b[38;5;129;01mor\u001b[39;00m trunc:\n",
      "File \u001b[1;32mc:\\Users\\giova\\anaconda3\\envs\\DRL\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giova\\anaconda3\\envs\\DRL\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\giova\\__UNI\\Deep Learning Applications\\DLA-Labs\\lab3\\gym_navigation\\envs\\navigation.py:61\u001b[0m, in \u001b[0;36mNavigation.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     58\u001b[0m     truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward, terminated, truncated, {}\n",
      "File \u001b[1;32mc:\\Users\\giova\\__UNI\\Deep Learning Applications\\DLA-Labs\\lab3\\gym_navigation\\envs\\navigation.py:140\u001b[0m, in \u001b[0;36mNavigation.render_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# We need to ensure that human-rendering occurs at the predefined framerate.\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Here, I try to solve the Navigation Goal environment using the provided REINFORCE implementation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium\n",
    "\n",
    "from reinforce import *\n",
    "from policy import *\n",
    "\n",
    "# In the new version of Gymnasium you need different environments for rendering and no rendering.\n",
    "# Here we instaintiate two versions of cartpole, one that animates the episodes (which slows everything\n",
    "# down), and another that does not animate.\n",
    "env = gymnasium.make('gym_navigation:NavigationGoal-v0', render_mode=None, track_id=1)\n",
    "env_render = gymnasium.make('gym_navigation:NavigationGoal-v0', render_mode='human')\n",
    "\n",
    "# Make a policy network.\n",
    "policy = PolicyNet(env, 64).to(device)\n",
    "\n",
    "# Train the agent.\n",
    "running  = reinforce(policy, env, env_render, device=device, lr=1e-4, num_episodes=100)\n",
    "running += reinforce(policy, env, env_render, device=device, lr=1e-5, num_episodes=100)\n",
    "plt.plot(running)\n",
    "\n",
    "# Close up everything\n",
    "env_render.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a9a01",
   "metadata": {},
   "source": [
    "I'll now try to implement my own version of the REINFORCE algorithm. Let's first test the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "d5d6f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "from policy import *\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "env_name = \"gym_navigation:NavigationGoal-v0\"\n",
    "hidden_size = 128\n",
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.989\n",
    "episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "72e92edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\giova\\__UNI\\Deep Learning Applications\\DLA-Labs\\lab3\\wandb\\run-20240131_012840-2u89ox6l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/giovancombo/navigation-goal/runs/2u89ox6l' target=\"_blank\">fragrant-shape-6</a></strong> to <a href='https://wandb.ai/giovancombo/navigation-goal' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/giovancombo/navigation-goal' target=\"_blank\">https://wandb.ai/giovancombo/navigation-goal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/giovancombo/navigation-goal/runs/2u89ox6l' target=\"_blank\">https://wandb.ai/giovancombo/navigation-goal/runs/2u89ox6l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, 13\tScore: -101.1562; Policy loss: 127.44\n",
      "Episode 2, 55\tScore: -115.3443; Policy loss: 90.34\n",
      "Episode 3, 39\tScore: -69.4699; Policy loss: 80.17\n",
      "Episode 4, 36\tScore: -115.1223; Policy loss: 101.48\n",
      "Episode 5, 26\tScore: -100.0161; Policy loss: 92.19\n",
      "Episode 6, 43\tScore: -104.3072; Policy loss: 94.81\n",
      "Episode 7, 51\tScore: -104.6188; Policy loss: 92.28\n",
      "Episode 8, 23\tScore: -100.1336; Policy loss: 110.68\n",
      "Episode 9, 32\tScore: -102.6616; Policy loss: 91.62\n",
      "Episode 10, 12\tScore: -108.2232; Policy loss: 99.08\n",
      "Episode 11, 22\tScore: -102.3085; Policy loss: 124.85\n",
      "Episode 12, 35\tScore: -116.3669; Policy loss: 105.26\n",
      "Episode 13, 36\tScore: -114.3873; Policy loss: 95.19\n",
      "Episode 14, 28\tScore: -108.9274; Policy loss: 109.72\n",
      "Episode 15, 13\tScore: -93.9534; Policy loss: 94.80\n",
      "Episode 16, 61\tScore: -112.6524; Policy loss: 86.21\n",
      "Episode 17, 9\tScore: -95.1236; Policy loss: 119.69\n",
      "Episode 18, 38\tScore: -100.5372; Policy loss: 90.25\n",
      "Episode 19, 65\tScore: -112.7306; Policy loss: 88.68\n",
      "Episode 20, 60\tScore: -117.8480; Policy loss: 90.27\n",
      "Episode 21, 16\tScore: -100.0000; Policy loss: 103.49\n",
      "Episode 22, 43\tScore: -71.9225; Policy loss: 80.73\n",
      "Episode 23, 45\tScore: -117.3146; Policy loss: 93.05\n",
      "Episode 24, 30\tScore: -87.7804; Policy loss: 93.87\n",
      "Episode 25, 32\tScore: 520.1565; Policy loss: -461.52\n",
      "Episode 26, 31\tScore: -107.3364; Policy loss: 98.29\n",
      "Episode 27, 27\tScore: -107.8088; Policy loss: 100.64\n",
      "Episode 28, 40\tScore: -114.8327; Policy loss: 98.96\n",
      "Episode 29, 74\tScore: -81.0269; Policy loss: 69.69\n",
      "Episode 30, 13\tScore: -100.0000; Policy loss: 100.43\n",
      "Episode 31, 40\tScore: 523.2279; Policy loss: -424.70\n",
      "Episode 32, 41\tScore: -100.0000; Policy loss: 90.17\n",
      "Episode 33, 26\tScore: -107.4173; Policy loss: 100.14\n",
      "Episode 34, 16\tScore: -91.9616; Policy loss: 99.54\n",
      "Episode 35, 12\tScore: -106.3085; Policy loss: 108.89\n",
      "Episode 36, 34\tScore: -98.1920; Policy loss: 93.77\n",
      "Episode 37, 9\tScore: -100.6127; Policy loss: 100.09\n",
      "Episode 38, 46\tScore: -110.2624; Policy loss: 93.47\n",
      "Episode 39, 15\tScore: -103.3388; Policy loss: 100.77\n",
      "Episode 40, 10\tScore: -102.7374; Policy loss: 104.60\n",
      "Episode 41, 13\tScore: -100.0234; Policy loss: 111.47\n",
      "Episode 42, 3\tScore: -100.0000; Policy loss: 102.12\n",
      "Episode 43, 43\tScore: -105.7404; Policy loss: 93.79\n",
      "Episode 44, 17\tScore: -79.7649; Policy loss: 88.90\n",
      "Episode 45, 16\tScore: -100.2615; Policy loss: 104.33\n",
      "Episode 46, 34\tScore: -110.9018; Policy loss: 96.68\n",
      "Episode 47, 28\tScore: -103.4054; Policy loss: 94.67\n",
      "Episode 48, 34\tScore: -112.3530; Policy loss: 94.22\n",
      "Episode 49, 37\tScore: -103.0345; Policy loss: 90.36\n",
      "Episode 50, 18\tScore: -104.4067; Policy loss: 105.91\n",
      "Episode 51, 28\tScore: -96.0365; Policy loss: 91.50\n",
      "Episode 52, 48\tScore: -103.6732; Policy loss: 89.24\n",
      "Episode 53, 20\tScore: -109.3103; Policy loss: 104.05\n",
      "Episode 54, 50\tScore: 511.4012; Policy loss: -443.10\n",
      "Episode 55, 19\tScore: -100.0000; Policy loss: 100.29\n",
      "Episode 56, 14\tScore: -100.6103; Policy loss: 99.82\n",
      "Episode 57, 26\tScore: -104.0727; Policy loss: 94.66\n",
      "Episode 58, 21\tScore: -103.1261; Policy loss: 103.96\n",
      "Episode 59, 19\tScore: -106.0251; Policy loss: 100.86\n",
      "Episode 60, 45\tScore: -112.6173; Policy loss: 92.51\n",
      "Episode 61, 31\tScore: -105.6371; Policy loss: 100.11\n",
      "Episode 62, 43\tScore: -93.1614; Policy loss: 89.16\n",
      "Episode 63, 31\tScore: -102.8661; Policy loss: 103.43\n",
      "Episode 64, 22\tScore: -104.4714; Policy loss: 103.17\n",
      "Episode 65, 43\tScore: -102.0410; Policy loss: 88.71\n",
      "Episode 66, 13\tScore: -100.0000; Policy loss: 100.32\n",
      "Episode 67, 74\tScore: -76.0909; Policy loss: 73.53\n",
      "Episode 68, 28\tScore: -102.5946; Policy loss: 95.67\n",
      "Episode 69, 30\tScore: -104.5598; Policy loss: 100.07\n",
      "Episode 70, 48\tScore: -108.1797; Policy loss: 93.91\n",
      "Episode 71, 43\tScore: -104.2541; Policy loss: 90.07\n",
      "Episode 72, 21\tScore: -96.5984; Policy loss: 100.50\n",
      "Episode 73, 17\tScore: -101.7962; Policy loss: 99.81\n",
      "Episode 74, 10\tScore: -100.0971; Policy loss: 106.46\n",
      "Episode 75, 17\tScore: -107.6120; Policy loss: 104.45\n",
      "Episode 76, 34\tScore: -95.9551; Policy loss: 89.92\n",
      "Episode 77, 8\tScore: -100.6900; Policy loss: 105.02\n",
      "Episode 78, 22\tScore: -100.0000; Policy loss: 95.68\n",
      "Episode 79, 95\tScore: -108.8216; Policy loss: 69.80\n",
      "Episode 80, 11\tScore: -100.0000; Policy loss: 111.08\n",
      "Episode 81, 32\tScore: -105.1424; Policy loss: 97.15\n",
      "Episode 82, 22\tScore: -99.8171; Policy loss: 98.20\n",
      "Episode 83, 9\tScore: -100.0000; Policy loss: 101.74\n",
      "Episode 84, 11\tScore: -101.5220; Policy loss: 105.54\n",
      "Episode 85, 33\tScore: -100.3592; Policy loss: 95.89\n",
      "Episode 86, 54\tScore: 506.3939; Policy loss: -437.14\n",
      "Episode 87, 9\tScore: -102.1142; Policy loss: 106.18\n",
      "Episode 88, 24\tScore: -101.6681; Policy loss: 101.01\n",
      "Episode 89, 35\tScore: -100.3570; Policy loss: 91.34\n",
      "Episode 90, 63\tScore: -109.3215; Policy loss: 84.46\n",
      "Episode 91, 20\tScore: -100.0000; Policy loss: 94.44\n",
      "Episode 92, 58\tScore: -83.4040; Policy loss: 81.18\n",
      "Episode 93, 33\tScore: -107.6755; Policy loss: 96.90\n",
      "Episode 94, 24\tScore: -91.8215; Policy loss: 92.39\n",
      "Episode 95, 34\tScore: -103.9451; Policy loss: 96.87\n",
      "Episode 96, 7\tScore: -100.6576; Policy loss: 104.93\n",
      "Episode 97, 62\tScore: -112.7925; Policy loss: 86.02\n",
      "Episode 98, 9\tScore: -100.0000; Policy loss: 106.95\n",
      "Episode 99, 47\tScore: -96.4212; Policy loss: 88.64\n",
      "Episode 100, 6\tScore: -100.0000; Policy loss: 75.36\n",
      "Episode 101, 66\tScore: -84.3886; Policy loss: 73.66\n",
      "Episode 102, 41\tScore: -103.8497; Policy loss: 87.20\n",
      "Episode 103, 20\tScore: -100.0000; Policy loss: 102.08\n",
      "Episode 104, 40\tScore: -102.9300; Policy loss: 91.82\n",
      "Episode 105, 62\tScore: 560.7549; Policy loss: -468.03\n",
      "Episode 106, 13\tScore: -100.7992; Policy loss: 100.31\n",
      "Episode 107, 48\tScore: -107.2602; Policy loss: 90.45\n",
      "Episode 108, 62\tScore: -113.6768; Policy loss: 90.50\n",
      "Episode 109, 49\tScore: -111.3500; Policy loss: 94.27\n",
      "Episode 110, 30\tScore: -100.0891; Policy loss: 98.65\n",
      "Episode 111, 19\tScore: -105.1771; Policy loss: 97.83\n",
      "Episode 112, 26\tScore: -84.4736; Policy loss: 91.16\n",
      "Episode 113, 22\tScore: -100.0000; Policy loss: 106.08\n",
      "Episode 114, 14\tScore: -102.9187; Policy loss: 114.76\n",
      "Episode 115, 47\tScore: -109.2067; Policy loss: 91.27\n",
      "Episode 116, 8\tScore: -105.6656; Policy loss: 102.66\n",
      "Episode 117, 25\tScore: -102.9618; Policy loss: 86.27\n",
      "Episode 118, 32\tScore: -99.8522; Policy loss: 93.25\n",
      "Episode 119, 56\tScore: -92.4837; Policy loss: 85.18\n",
      "Episode 120, 16\tScore: -100.0000; Policy loss: 102.87\n",
      "Episode 121, 20\tScore: -102.8545; Policy loss: 112.33\n",
      "Episode 122, 18\tScore: -100.8376; Policy loss: 101.19\n",
      "Episode 123, 25\tScore: -100.8921; Policy loss: 85.34\n",
      "Episode 124, 9\tScore: -100.0000; Policy loss: 113.35\n",
      "Episode 125, 48\tScore: -108.5558; Policy loss: 90.13\n",
      "Episode 126, 34\tScore: 539.8490; Policy loss: -481.38\n",
      "Episode 127, 28\tScore: -87.5699; Policy loss: 85.41\n",
      "Episode 128, 40\tScore: -104.1990; Policy loss: 90.10\n",
      "Episode 129, 39\tScore: -115.7977; Policy loss: 95.58\n",
      "Episode 130, 14\tScore: -98.3140; Policy loss: 103.79\n",
      "Episode 131, 45\tScore: -112.3525; Policy loss: 90.91\n",
      "Episode 132, 70\tScore: -106.8122; Policy loss: 78.21\n",
      "Episode 133, 15\tScore: -82.2485; Policy loss: 92.20\n",
      "Episode 134, 18\tScore: -100.0000; Policy loss: 91.89\n",
      "Episode 135, 13\tScore: -87.9394; Policy loss: 96.38\n",
      "Episode 136, 11\tScore: -100.0000; Policy loss: 107.82\n",
      "Episode 137, 17\tScore: -102.3839; Policy loss: 98.25\n",
      "Episode 138, 22\tScore: -93.0102; Policy loss: 96.19\n",
      "Episode 139, 4\tScore: -97.5291; Policy loss: 102.05\n",
      "Episode 140, 64\tScore: -116.5809; Policy loss: 90.40\n",
      "Episode 141, 25\tScore: -102.9224; Policy loss: 103.76\n",
      "Episode 142, 20\tScore: -101.3208; Policy loss: 99.41\n",
      "Episode 143, 43\tScore: -77.4735; Policy loss: 83.34\n",
      "Episode 144, 44\tScore: -118.6447; Policy loss: 97.41\n",
      "Episode 145, 10\tScore: -100.0711; Policy loss: 108.87\n",
      "Episode 146, 20\tScore: -102.9547; Policy loss: 102.89\n",
      "Episode 147, 19\tScore: -100.1773; Policy loss: 95.60\n",
      "Episode 148, 73\tScore: -133.5735; Policy loss: 93.29\n",
      "Episode 149, 33\tScore: -100.0000; Policy loss: 92.44\n",
      "Episode 150, 7\tScore: -99.3111; Policy loss: 105.40\n",
      "Episode 151, 17\tScore: -100.0729; Policy loss: 97.56\n",
      "Episode 152, 25\tScore: -113.2501; Policy loss: 107.56\n",
      "Episode 153, 38\tScore: -100.0000; Policy loss: 89.19\n",
      "Episode 154, 9\tScore: -101.3232; Policy loss: 97.26\n",
      "Episode 155, 6\tScore: -99.4465; Policy loss: 109.19\n",
      "Episode 156, 49\tScore: -95.1548; Policy loss: 85.67\n",
      "Episode 157, 12\tScore: -99.9516; Policy loss: 102.19\n",
      "Episode 158, 12\tScore: -89.4788; Policy loss: 91.32\n",
      "Episode 159, 20\tScore: -108.3876; Policy loss: 101.43\n",
      "Episode 160, 56\tScore: -119.3534; Policy loss: 90.91\n",
      "Episode 161, 11\tScore: -99.1995; Policy loss: 113.06\n",
      "Episode 162, 24\tScore: -110.5868; Policy loss: 102.09\n",
      "Episode 163, 39\tScore: -101.0149; Policy loss: 91.78\n",
      "Episode 164, 15\tScore: -103.5807; Policy loss: 108.42\n",
      "Episode 165, 15\tScore: -105.3023; Policy loss: 101.91\n",
      "Episode 166, 34\tScore: -116.4300; Policy loss: 96.67\n",
      "Episode 167, 30\tScore: -93.2823; Policy loss: 92.62\n",
      "Episode 168, 35\tScore: -101.1763; Policy loss: 89.26\n",
      "Episode 169, 25\tScore: -103.4161; Policy loss: 95.54\n",
      "Episode 170, 35\tScore: -106.9829; Policy loss: 93.74\n",
      "Episode 171, 52\tScore: -106.7894; Policy loss: 83.58\n",
      "Episode 172, 8\tScore: -97.4870; Policy loss: 107.30\n",
      "Episode 173, 23\tScore: -103.4127; Policy loss: 96.35\n",
      "Episode 174, 13\tScore: -100.0000; Policy loss: 101.99\n",
      "Episode 175, 28\tScore: -111.4341; Policy loss: 101.69\n",
      "Episode 176, 32\tScore: -102.6622; Policy loss: 93.22\n",
      "Episode 177, 9\tScore: -100.4017; Policy loss: 103.24\n",
      "Episode 178, 8\tScore: -99.3933; Policy loss: 96.36\n",
      "Episode 179, 35\tScore: 535.0914; Policy loss: -469.28\n",
      "Episode 180, 65\tScore: -80.1955; Policy loss: 78.42\n",
      "Episode 181, 21\tScore: -99.2436; Policy loss: 99.46\n",
      "Episode 182, 16\tScore: -100.0000; Policy loss: 94.76\n",
      "Episode 183, 19\tScore: -102.8090; Policy loss: 101.22\n",
      "Episode 184, 34\tScore: 539.8006; Policy loss: -477.34\n",
      "Episode 185, 32\tScore: -110.6507; Policy loss: 97.27\n",
      "Episode 186, 24\tScore: -105.6770; Policy loss: 93.47\n",
      "Episode 187, 39\tScore: -107.1640; Policy loss: 94.83\n",
      "Episode 188, 6\tScore: -100.0000; Policy loss: 104.46\n",
      "Episode 189, 16\tScore: -82.9021; Policy loss: 89.66\n",
      "Episode 190, 35\tScore: 528.1621; Policy loss: -446.19\n",
      "Episode 191, 23\tScore: -102.8001; Policy loss: 95.68\n",
      "Episode 192, 16\tScore: -101.1258; Policy loss: 99.24\n",
      "Episode 193, 9\tScore: -100.0000; Policy loss: 121.00\n",
      "Episode 194, 11\tScore: -105.2795; Policy loss: 93.53\n",
      "Episode 195, 26\tScore: -106.0413; Policy loss: 96.18\n",
      "Episode 196, 17\tScore: -89.1794; Policy loss: 96.57\n",
      "Episode 197, 20\tScore: -100.0205; Policy loss: 92.07\n",
      "Episode 198, 17\tScore: -105.0064; Policy loss: 105.34\n",
      "Episode 199, 43\tScore: -97.2918; Policy loss: 93.82\n",
      "Episode 200, 39\tScore: -90.8115; Policy loss: 88.88\n",
      "Episode 201, 70\tScore: -107.2245; Policy loss: 85.29\n",
      "Episode 202, 9\tScore: -102.9924; Policy loss: 101.07\n",
      "Episode 203, 15\tScore: -103.6542; Policy loss: 97.21\n",
      "Episode 204, 9\tScore: -100.2817; Policy loss: 99.40\n",
      "Episode 205, 34\tScore: -72.3798; Policy loss: 78.63\n",
      "Episode 206, 44\tScore: -106.9061; Policy loss: 98.80\n",
      "Episode 207, 15\tScore: -102.5886; Policy loss: 102.14\n",
      "Episode 208, 17\tScore: -100.6214; Policy loss: 98.78\n",
      "Episode 209, 13\tScore: -100.0028; Policy loss: 94.15\n",
      "Episode 210, 15\tScore: -102.0477; Policy loss: 97.49\n",
      "Episode 211, 10\tScore: -87.4131; Policy loss: 99.23\n",
      "Episode 212, 13\tScore: -100.0000; Policy loss: 102.27\n",
      "Episode 213, 34\tScore: -100.2099; Policy loss: 91.56\n",
      "Episode 214, 26\tScore: -107.2758; Policy loss: 100.70\n",
      "Episode 215, 14\tScore: -104.5029; Policy loss: 102.17\n",
      "Episode 216, 17\tScore: -104.3076; Policy loss: 96.97\n",
      "Episode 217, 43\tScore: -108.8855; Policy loss: 91.76\n",
      "Episode 218, 7\tScore: -100.0000; Policy loss: 96.81\n",
      "Episode 219, 28\tScore: -107.3316; Policy loss: 99.81\n",
      "Episode 220, 9\tScore: -102.0923; Policy loss: 97.18\n",
      "Episode 221, 33\tScore: -101.1840; Policy loss: 94.47\n",
      "Episode 222, 16\tScore: -103.4265; Policy loss: 103.48\n",
      "Episode 223, 16\tScore: -108.7983; Policy loss: 104.05\n",
      "Episode 224, 32\tScore: -89.9080; Policy loss: 91.49\n",
      "Episode 225, 7\tScore: -103.3322; Policy loss: 93.32\n",
      "Episode 226, 25\tScore: -108.2352; Policy loss: 100.28\n",
      "Episode 227, 40\tScore: -105.7405; Policy loss: 88.97\n",
      "Episode 228, 7\tScore: -102.4616; Policy loss: 104.83\n",
      "Episode 229, 23\tScore: -101.7254; Policy loss: 97.81\n",
      "Episode 230, 15\tScore: -104.4900; Policy loss: 113.93\n",
      "Episode 231, 26\tScore: -100.0000; Policy loss: 87.08\n",
      "Episode 232, 10\tScore: -100.0000; Policy loss: 93.36\n",
      "Episode 233, 14\tScore: -100.0000; Policy loss: 100.31\n",
      "Episode 234, 16\tScore: -106.1189; Policy loss: 94.63\n",
      "Episode 235, 30\tScore: -111.6309; Policy loss: 109.60\n",
      "Episode 236, 19\tScore: -100.6393; Policy loss: 103.04\n",
      "Episode 237, 36\tScore: -102.6313; Policy loss: 93.23\n",
      "Episode 238, 30\tScore: 535.0373; Policy loss: -500.55\n",
      "Episode 239, 19\tScore: -102.1148; Policy loss: 107.24\n",
      "Episode 240, 24\tScore: -72.8586; Policy loss: 93.81\n",
      "Episode 241, 73\tScore: -129.7470; Policy loss: 92.72\n",
      "Episode 242, 15\tScore: -103.4796; Policy loss: 106.15\n",
      "Episode 243, 24\tScore: -106.6679; Policy loss: 94.43\n",
      "Episode 244, 27\tScore: -105.4778; Policy loss: 106.79\n",
      "Episode 245, 17\tScore: -100.5188; Policy loss: 104.84\n",
      "Episode 246, 32\tScore: -103.8702; Policy loss: 96.67\n",
      "Episode 247, 26\tScore: -95.9224; Policy loss: 97.74\n",
      "Episode 248, 11\tScore: -100.1270; Policy loss: 95.69\n",
      "Episode 249, 17\tScore: -105.6316; Policy loss: 98.45\n",
      "Episode 250, 20\tScore: -104.1448; Policy loss: 100.23\n",
      "Episode 251, 22\tScore: -100.0000; Policy loss: 97.00\n",
      "Episode 252, 16\tScore: -105.2226; Policy loss: 113.43\n",
      "Episode 253, 18\tScore: -107.1280; Policy loss: 99.16\n",
      "Episode 254, 24\tScore: -110.6776; Policy loss: 107.08\n",
      "Episode 255, 30\tScore: 544.7378; Policy loss: -477.26\n",
      "Episode 256, 28\tScore: -101.7940; Policy loss: 99.28\n",
      "Episode 257, 55\tScore: -91.3293; Policy loss: 86.71\n",
      "Episode 258, 34\tScore: -100.0000; Policy loss: 90.63\n",
      "Episode 259, 33\tScore: -100.0000; Policy loss: 93.17\n",
      "Episode 260, 39\tScore: -114.2997; Policy loss: 96.81\n",
      "Episode 261, 19\tScore: -105.8750; Policy loss: 101.49\n",
      "Episode 262, 18\tScore: -100.0000; Policy loss: 99.77\n",
      "Episode 263, 44\tScore: -83.4292; Policy loss: 81.70\n",
      "Episode 264, 25\tScore: -107.3721; Policy loss: 102.02\n",
      "Episode 265, 13\tScore: -85.5060; Policy loss: 90.57\n",
      "Episode 266, 44\tScore: 526.6838; Policy loss: -473.20\n",
      "Episode 267, 41\tScore: -90.6418; Policy loss: 88.79\n",
      "Episode 268, 32\tScore: -100.4884; Policy loss: 93.83\n",
      "Episode 269, 15\tScore: -100.8927; Policy loss: 100.80\n",
      "Episode 270, 30\tScore: -109.5280; Policy loss: 97.17\n",
      "Episode 271, 8\tScore: -100.0000; Policy loss: 99.36\n",
      "Episode 272, 7\tScore: -100.2427; Policy loss: 102.40\n",
      "Episode 273, 43\tScore: -104.5690; Policy loss: 84.80\n",
      "Episode 274, 34\tScore: -77.6601; Policy loss: 89.20\n",
      "Episode 275, 26\tScore: 537.3445; Policy loss: -508.43\n",
      "Episode 276, 8\tScore: -100.0000; Policy loss: 103.17\n",
      "Episode 277, 23\tScore: -100.0000; Policy loss: 93.96\n",
      "Episode 278, 10\tScore: -100.0000; Policy loss: 107.56\n",
      "Episode 279, 14\tScore: -101.8366; Policy loss: 103.82\n",
      "Episode 280, 50\tScore: -104.1950; Policy loss: 91.31\n",
      "Episode 281, 23\tScore: -99.7660; Policy loss: 95.42\n",
      "Episode 282, 7\tScore: -100.0000; Policy loss: 107.99\n",
      "Episode 283, 23\tScore: -109.2627; Policy loss: 103.95\n",
      "Episode 284, 11\tScore: -102.5076; Policy loss: 99.54\n",
      "Episode 285, 9\tScore: -100.0000; Policy loss: 117.65\n",
      "Episode 286, 22\tScore: -106.3445; Policy loss: 100.65\n",
      "Episode 287, 36\tScore: -102.0385; Policy loss: 90.28\n",
      "Episode 288, 7\tScore: -100.0000; Policy loss: 115.89\n",
      "Episode 289, 35\tScore: -113.7684; Policy loss: 98.22\n",
      "Episode 290, 8\tScore: -88.4122; Policy loss: 99.45\n",
      "Episode 291, 41\tScore: -101.0419; Policy loss: 91.93\n",
      "Episode 292, 15\tScore: -100.0757; Policy loss: 103.34\n",
      "Episode 293, 41\tScore: -125.2164; Policy loss: 103.43\n",
      "Episode 294, 10\tScore: -100.0000; Policy loss: 106.59\n",
      "Episode 295, 26\tScore: -100.0000; Policy loss: 92.45\n",
      "Episode 296, 8\tScore: -100.0000; Policy loss: 104.94\n",
      "Episode 297, 33\tScore: -104.5387; Policy loss: 94.02\n",
      "Episode 298, 16\tScore: -101.7315; Policy loss: 98.79\n",
      "Episode 299, 24\tScore: -102.7532; Policy loss: 96.03\n",
      "Episode 300, 25\tScore: -109.2686; Policy loss: 103.19\n",
      "Episode 301, 23\tScore: -100.3827; Policy loss: 96.84\n",
      "Episode 302, 37\tScore: -100.7578; Policy loss: 88.90\n",
      "Episode 303, 34\tScore: -73.1536; Policy loss: 90.92\n",
      "Episode 304, 52\tScore: -81.3175; Policy loss: 79.49\n",
      "Episode 305, 47\tScore: -114.9099; Policy loss: 89.24\n",
      "Episode 306, 17\tScore: -100.7486; Policy loss: 101.06\n",
      "Episode 307, 14\tScore: -107.2851; Policy loss: 107.53\n",
      "Episode 308, 59\tScore: -104.0081; Policy loss: 82.65\n",
      "Episode 309, 23\tScore: -102.5198; Policy loss: 97.29\n",
      "Episode 310, 17\tScore: -100.0000; Policy loss: 90.19\n",
      "Episode 311, 21\tScore: -100.8685; Policy loss: 100.59\n",
      "Episode 312, 29\tScore: -96.8388; Policy loss: 94.29\n",
      "Episode 313, 6\tScore: -100.0000; Policy loss: 99.77\n",
      "Episode 314, 8\tScore: -104.5840; Policy loss: 101.55\n",
      "Episode 315, 54\tScore: -94.3459; Policy loss: 81.60\n",
      "Episode 316, 22\tScore: -108.5621; Policy loss: 109.49\n",
      "Episode 317, 14\tScore: -108.4829; Policy loss: 113.04\n",
      "Episode 318, 38\tScore: -108.5667; Policy loss: 91.01\n",
      "Episode 319, 28\tScore: -90.1259; Policy loss: 94.65\n",
      "Episode 320, 12\tScore: -83.0875; Policy loss: 95.11\n",
      "Episode 321, 12\tScore: -100.4054; Policy loss: 104.55\n",
      "Episode 322, 39\tScore: -104.1349; Policy loss: 91.68\n",
      "Episode 323, 39\tScore: 542.6363; Policy loss: -471.47\n",
      "Episode 324, 8\tScore: -100.0000; Policy loss: 105.53\n",
      "Episode 325, 8\tScore: -100.0000; Policy loss: 110.18\n",
      "Episode 326, 34\tScore: -102.7312; Policy loss: 94.17\n",
      "Episode 327, 5\tScore: -98.2631; Policy loss: 87.44\n",
      "Episode 328, 31\tScore: -106.3210; Policy loss: 93.37\n",
      "Episode 329, 46\tScore: -99.1166; Policy loss: 83.01\n",
      "Episode 330, 25\tScore: -97.9277; Policy loss: 98.22\n",
      "Episode 331, 39\tScore: -109.9316; Policy loss: 87.69\n",
      "Episode 332, 35\tScore: -100.0466; Policy loss: 90.07\n",
      "Episode 333, 36\tScore: -104.2416; Policy loss: 98.10\n",
      "Episode 334, 30\tScore: 525.8281; Policy loss: -488.30\n",
      "Episode 335, 31\tScore: -106.9017; Policy loss: 97.97\n",
      "Episode 336, 8\tScore: -100.0000; Policy loss: 97.74\n",
      "Episode 337, 21\tScore: -103.3447; Policy loss: 99.44\n",
      "Episode 338, 45\tScore: -104.8225; Policy loss: 90.43\n",
      "Episode 339, 32\tScore: 521.1646; Policy loss: -492.84\n",
      "Episode 340, 10\tScore: -100.3779; Policy loss: 102.08\n",
      "Episode 341, 25\tScore: -100.9385; Policy loss: 103.88\n",
      "Episode 342, 18\tScore: -100.0246; Policy loss: 105.31\n",
      "Episode 343, 5\tScore: -100.0000; Policy loss: 104.59\n",
      "Episode 344, 52\tScore: -106.9880; Policy loss: 87.52\n",
      "Episode 345, 10\tScore: -100.9649; Policy loss: 103.00\n",
      "Episode 346, 18\tScore: -104.1327; Policy loss: 107.76\n",
      "Episode 347, 20\tScore: -102.7684; Policy loss: 99.12\n",
      "Episode 348, 18\tScore: -100.0000; Policy loss: 102.71\n",
      "Episode 349, 10\tScore: -94.5313; Policy loss: 97.82\n",
      "Episode 350, 19\tScore: -100.0065; Policy loss: 96.10\n",
      "Episode 351, 23\tScore: -100.0000; Policy loss: 100.36\n",
      "Episode 352, 22\tScore: -102.1138; Policy loss: 96.26\n",
      "Episode 353, 23\tScore: -109.5629; Policy loss: 97.19\n",
      "Episode 354, 23\tScore: -99.0419; Policy loss: 106.11\n",
      "Episode 355, 22\tScore: -100.4916; Policy loss: 106.76\n",
      "Episode 356, 5\tScore: -100.0000; Policy loss: 106.57\n",
      "Episode 357, 48\tScore: 553.4841; Policy loss: -460.96\n",
      "Episode 358, 25\tScore: -101.0103; Policy loss: 99.36\n",
      "Episode 359, 10\tScore: -86.5535; Policy loss: 111.14\n",
      "Episode 360, 22\tScore: -81.2460; Policy loss: 93.23\n",
      "Episode 361, 30\tScore: -110.2043; Policy loss: 99.94\n",
      "Episode 362, 59\tScore: -107.0620; Policy loss: 80.85\n",
      "Episode 363, 42\tScore: -105.1947; Policy loss: 88.12\n",
      "Episode 364, 33\tScore: 536.7463; Policy loss: -505.55\n",
      "Episode 365, 7\tScore: -98.4861; Policy loss: 96.20\n",
      "Episode 366, 10\tScore: -99.6704; Policy loss: 99.91\n",
      "Episode 367, 25\tScore: 529.1614; Policy loss: -550.13\n",
      "Episode 368, 37\tScore: -103.5743; Policy loss: 90.11\n",
      "Episode 369, 33\tScore: -103.1941; Policy loss: 91.91\n",
      "Episode 370, 15\tScore: -105.3463; Policy loss: 104.86\n",
      "Episode 371, 47\tScore: -79.1729; Policy loss: 80.55\n",
      "Episode 372, 17\tScore: -106.3920; Policy loss: 107.81\n",
      "Episode 373, 20\tScore: -100.1894; Policy loss: 102.15\n",
      "Episode 374, 33\tScore: -100.0453; Policy loss: 95.73\n",
      "Episode 375, 16\tScore: -108.7976; Policy loss: 112.81\n",
      "Episode 376, 22\tScore: -101.0877; Policy loss: 99.47\n",
      "Episode 377, 33\tScore: -109.6807; Policy loss: 105.22\n",
      "Episode 378, 21\tScore: -102.7560; Policy loss: 101.70\n",
      "Episode 379, 16\tScore: -100.1956; Policy loss: 109.69\n",
      "Episode 380, 19\tScore: -102.7823; Policy loss: 100.87\n",
      "Episode 381, 10\tScore: -100.0082; Policy loss: 95.21\n",
      "Episode 382, 43\tScore: -103.3652; Policy loss: 93.70\n",
      "Episode 383, 8\tScore: -98.4267; Policy loss: 105.18\n",
      "Episode 384, 15\tScore: -100.0000; Policy loss: 98.77\n",
      "Episode 385, 46\tScore: -80.0401; Policy loss: 85.15\n",
      "Episode 386, 40\tScore: -104.3655; Policy loss: 98.80\n",
      "Episode 387, 40\tScore: -98.3616; Policy loss: 89.05\n",
      "Episode 388, 19\tScore: -100.9319; Policy loss: 100.38\n",
      "Episode 389, 35\tScore: -101.2664; Policy loss: 89.17\n",
      "Episode 390, 14\tScore: -100.5835; Policy loss: 111.76\n",
      "Episode 391, 15\tScore: -99.8938; Policy loss: 107.48\n",
      "Episode 392, 58\tScore: -105.5465; Policy loss: 82.85\n",
      "Episode 393, 35\tScore: -100.3791; Policy loss: 93.13\n",
      "Episode 394, 38\tScore: -100.0000; Policy loss: 91.33\n",
      "Episode 395, 11\tScore: -100.7181; Policy loss: 100.52\n",
      "Episode 396, 35\tScore: -100.0000; Policy loss: 90.92\n",
      "Episode 397, 8\tScore: -102.9654; Policy loss: 98.81\n",
      "Episode 398, 40\tScore: -100.0896; Policy loss: 91.93\n",
      "Episode 399, 26\tScore: -96.5844; Policy loss: 91.07\n",
      "Episode 400, 44\tScore: -114.7595; Policy loss: 95.81\n",
      "Episode 401, 22\tScore: -100.9103; Policy loss: 100.76\n",
      "Episode 402, 50\tScore: -115.9410; Policy loss: 91.03\n",
      "Episode 403, 28\tScore: 525.1716; Policy loss: -505.94\n",
      "Episode 404, 13\tScore: -100.7566; Policy loss: 102.59\n",
      "Episode 405, 15\tScore: -106.6739; Policy loss: 111.29\n",
      "Episode 406, 29\tScore: -106.4381; Policy loss: 92.54\n",
      "Episode 407, 9\tScore: -100.0000; Policy loss: 110.22\n",
      "Episode 408, 32\tScore: -108.5764; Policy loss: 96.03\n",
      "Episode 409, 22\tScore: -102.8927; Policy loss: 102.44\n",
      "Episode 410, 10\tScore: -100.0000; Policy loss: 112.83\n",
      "Episode 411, 23\tScore: -101.3702; Policy loss: 99.45\n",
      "Episode 412, 20\tScore: -102.5501; Policy loss: 94.29\n",
      "Episode 413, 23\tScore: -112.5682; Policy loss: 105.93\n",
      "Episode 414, 14\tScore: -100.0000; Policy loss: 102.79\n",
      "Episode 415, 23\tScore: -69.0127; Policy loss: 82.60\n",
      "Episode 416, 33\tScore: -101.9662; Policy loss: 93.50\n",
      "Episode 417, 27\tScore: -111.1818; Policy loss: 105.73\n",
      "Episode 418, 24\tScore: -101.5317; Policy loss: 100.01\n",
      "Episode 419, 6\tScore: -100.0424; Policy loss: 112.56\n",
      "Episode 420, 37\tScore: -108.3048; Policy loss: 91.66\n",
      "Episode 421, 5\tScore: -102.9483; Policy loss: 107.92\n",
      "Episode 422, 19\tScore: -106.4716; Policy loss: 111.69\n",
      "Episode 423, 31\tScore: -111.2402; Policy loss: 102.40\n",
      "Episode 424, 25\tScore: -100.0000; Policy loss: 103.42\n",
      "Episode 425, 24\tScore: -100.0474; Policy loss: 97.92\n",
      "Episode 426, 15\tScore: -106.6935; Policy loss: 104.13\n",
      "Episode 427, 24\tScore: -105.0858; Policy loss: 98.47\n",
      "Episode 428, 11\tScore: -100.0000; Policy loss: 108.42\n",
      "Episode 429, 51\tScore: 569.0690; Policy loss: -464.94\n",
      "Episode 430, 11\tScore: -100.6331; Policy loss: 107.96\n",
      "Episode 431, 65\tScore: -85.1381; Policy loss: 84.83\n",
      "Episode 432, 44\tScore: -76.1251; Policy loss: 85.45\n",
      "Episode 433, 9\tScore: -90.5337; Policy loss: 97.98\n",
      "Episode 434, 21\tScore: -100.1365; Policy loss: 95.12\n",
      "Episode 435, 47\tScore: -101.3366; Policy loss: 90.66\n",
      "Episode 436, 11\tScore: -100.0000; Policy loss: 95.23\n",
      "Episode 437, 10\tScore: -100.0000; Policy loss: 105.36\n",
      "Episode 438, 13\tScore: -106.9991; Policy loss: 110.84\n",
      "Episode 439, 21\tScore: -108.1367; Policy loss: 104.11\n",
      "Episode 440, 15\tScore: -100.0000; Policy loss: 103.15\n",
      "Episode 441, 32\tScore: -103.6338; Policy loss: 92.34\n",
      "Episode 442, 35\tScore: 554.5611; Policy loss: -519.49\n",
      "Episode 443, 38\tScore: -106.8465; Policy loss: 91.84\n",
      "Episode 444, 11\tScore: -100.0000; Policy loss: 110.65\n",
      "Episode 445, 35\tScore: -100.1548; Policy loss: 89.77\n",
      "Episode 446, 44\tScore: -116.5269; Policy loss: 95.87\n",
      "Episode 447, 14\tScore: -100.8037; Policy loss: 102.01\n",
      "Episode 448, 28\tScore: -102.6896; Policy loss: 92.59\n",
      "Episode 449, 11\tScore: -101.5672; Policy loss: 99.97\n",
      "Episode 450, 28\tScore: 527.2550; Policy loss: -476.87\n",
      "Episode 451, 50\tScore: -108.2375; Policy loss: 91.20\n",
      "Episode 452, 7\tScore: -102.3597; Policy loss: 105.53\n",
      "Episode 453, 30\tScore: -100.0155; Policy loss: 92.69\n",
      "Episode 454, 39\tScore: -102.4121; Policy loss: 88.29\n",
      "Episode 455, 65\tScore: -97.6567; Policy loss: 82.11\n",
      "Episode 456, 19\tScore: -100.0000; Policy loss: 101.85\n",
      "Episode 457, 36\tScore: -90.7445; Policy loss: 79.16\n",
      "Episode 458, 18\tScore: -83.8107; Policy loss: 103.11\n",
      "Episode 459, 8\tScore: -102.0065; Policy loss: 110.96\n",
      "Episode 460, 39\tScore: -86.2165; Policy loss: 88.90\n",
      "Episode 461, 10\tScore: -100.0000; Policy loss: 98.83\n",
      "Episode 462, 23\tScore: -110.2273; Policy loss: 104.61\n",
      "Episode 463, 37\tScore: -104.6414; Policy loss: 90.56\n",
      "Episode 464, 35\tScore: -96.5851; Policy loss: 101.09\n",
      "Episode 465, 36\tScore: -100.2880; Policy loss: 92.93\n",
      "Episode 466, 34\tScore: -106.2775; Policy loss: 94.32\n",
      "Episode 467, 46\tScore: -106.3296; Policy loss: 84.89\n",
      "Episode 468, 10\tScore: -100.0000; Policy loss: 103.16\n",
      "Episode 469, 67\tScore: -117.5897; Policy loss: 92.47\n",
      "Episode 470, 17\tScore: -102.9701; Policy loss: 105.59\n",
      "Episode 471, 35\tScore: -109.6232; Policy loss: 100.07\n",
      "Episode 472, 32\tScore: -106.1143; Policy loss: 100.45\n",
      "Episode 473, 9\tScore: -103.3107; Policy loss: 101.67\n",
      "Episode 474, 34\tScore: -101.1179; Policy loss: 91.01\n",
      "Episode 475, 55\tScore: -95.6863; Policy loss: 83.79\n",
      "Episode 476, 19\tScore: -100.0000; Policy loss: 98.60\n",
      "Episode 477, 26\tScore: -92.0847; Policy loss: 91.49\n",
      "Episode 478, 28\tScore: -100.8286; Policy loss: 93.92\n",
      "Episode 479, 30\tScore: -103.4724; Policy loss: 97.84\n",
      "Episode 480, 22\tScore: -94.0943; Policy loss: 95.61\n",
      "Episode 481, 57\tScore: -81.0601; Policy loss: 77.23\n",
      "Episode 482, 9\tScore: -100.0000; Policy loss: 109.43\n",
      "Episode 483, 28\tScore: -100.2508; Policy loss: 92.90\n",
      "Episode 484, 42\tScore: -100.8275; Policy loss: 90.13\n",
      "Episode 485, 10\tScore: -101.4621; Policy loss: 105.34\n",
      "Episode 486, 27\tScore: -100.0000; Policy loss: 98.92\n",
      "Episode 487, 26\tScore: -100.0000; Policy loss: 93.64\n",
      "Episode 488, 57\tScore: -108.4128; Policy loss: 90.90\n",
      "Episode 489, 70\tScore: -107.4247; Policy loss: 81.18\n",
      "Episode 490, 37\tScore: -104.4541; Policy loss: 92.25\n",
      "Episode 491, 21\tScore: -108.5381; Policy loss: 100.10\n",
      "Episode 492, 46\tScore: -110.4129; Policy loss: 89.70\n",
      "Episode 493, 12\tScore: -105.5938; Policy loss: 102.10\n",
      "Episode 494, 15\tScore: -104.0296; Policy loss: 102.89\n",
      "Episode 495, 32\tScore: -100.0000; Policy loss: 93.02\n",
      "Episode 496, 14\tScore: -104.2506; Policy loss: 106.94\n",
      "Episode 497, 22\tScore: -90.2277; Policy loss: 94.36\n",
      "Episode 498, 18\tScore: -107.8291; Policy loss: 101.77\n",
      "Episode 499, 11\tScore: -100.4044; Policy loss: 108.51\n",
      "Episode 500, 57\tScore: -85.7080; Policy loss: 82.80\n",
      "Episode 501, 6\tScore: -100.0000; Policy loss: 98.61\n",
      "Episode 502, 20\tScore: -103.8512; Policy loss: 106.21\n",
      "Episode 503, 40\tScore: -84.5752; Policy loss: 89.45\n",
      "Episode 504, 10\tScore: -105.7725; Policy loss: 107.64\n",
      "Episode 505, 26\tScore: -94.1915; Policy loss: 94.97\n",
      "Episode 506, 22\tScore: -101.3471; Policy loss: 98.43\n",
      "Episode 507, 49\tScore: -113.4605; Policy loss: 93.38\n",
      "Episode 508, 39\tScore: -78.0744; Policy loss: 87.60\n",
      "Episode 509, 42\tScore: -110.5540; Policy loss: 93.09\n",
      "Episode 510, 34\tScore: -106.4916; Policy loss: 96.72\n",
      "Episode 511, 56\tScore: -114.1178; Policy loss: 90.10\n",
      "Episode 512, 24\tScore: -102.5976; Policy loss: 94.07\n",
      "Episode 513, 40\tScore: 551.4734; Policy loss: -477.37\n",
      "Episode 514, 46\tScore: -109.9493; Policy loss: 89.99\n",
      "Episode 515, 7\tScore: -100.0000; Policy loss: 102.06\n",
      "Episode 516, 14\tScore: -100.0000; Policy loss: 101.33\n",
      "Episode 517, 27\tScore: -110.4548; Policy loss: 99.61\n",
      "Episode 518, 40\tScore: -104.3849; Policy loss: 95.65\n",
      "Episode 519, 30\tScore: 522.3891; Policy loss: -489.56\n",
      "Episode 520, 42\tScore: -108.6376; Policy loss: 95.84\n",
      "Episode 521, 26\tScore: 529.3912; Policy loss: -501.84\n",
      "Episode 522, 7\tScore: -100.3092; Policy loss: 98.23\n",
      "Episode 523, 9\tScore: -100.0000; Policy loss: 102.67\n",
      "Episode 524, 12\tScore: -99.9450; Policy loss: 101.00\n",
      "Episode 525, 11\tScore: -101.8947; Policy loss: 118.20\n",
      "Episode 526, 5\tScore: -100.0000; Policy loss: 107.98\n",
      "Episode 527, 36\tScore: 548.0029; Policy loss: -485.74\n",
      "Episode 528, 36\tScore: 547.7188; Policy loss: -502.31\n",
      "Episode 529, 43\tScore: -113.9454; Policy loss: 93.10\n",
      "Episode 530, 24\tScore: -100.8936; Policy loss: 94.74\n",
      "Episode 531, 38\tScore: -102.7839; Policy loss: 94.85\n",
      "Episode 532, 27\tScore: -112.4810; Policy loss: 104.29\n",
      "Episode 533, 41\tScore: -108.1641; Policy loss: 94.89\n",
      "Episode 534, 36\tScore: -109.8923; Policy loss: 94.72\n",
      "Episode 535, 69\tScore: -125.0031; Policy loss: 93.45\n",
      "Episode 536, 11\tScore: -102.4519; Policy loss: 102.69\n",
      "Episode 537, 15\tScore: -100.1381; Policy loss: 98.69\n",
      "Episode 538, 19\tScore: -101.7661; Policy loss: 100.72\n",
      "Episode 539, 8\tScore: -100.0000; Policy loss: 111.25\n",
      "Episode 540, 7\tScore: -93.0492; Policy loss: 109.31\n",
      "Episode 541, 46\tScore: -115.1219; Policy loss: 97.87\n",
      "Episode 542, 11\tScore: -100.0000; Policy loss: 108.08\n",
      "Episode 543, 32\tScore: -108.1482; Policy loss: 98.08\n",
      "Episode 544, 23\tScore: -108.0615; Policy loss: 98.34\n",
      "Episode 545, 19\tScore: -96.2989; Policy loss: 100.11\n",
      "Episode 546, 30\tScore: 521.2730; Policy loss: -485.05\n",
      "Episode 547, 16\tScore: -105.0840; Policy loss: 94.12\n",
      "Episode 548, 30\tScore: -101.3010; Policy loss: 96.63\n",
      "Episode 549, 17\tScore: -100.0000; Policy loss: 98.53\n",
      "Episode 550, 30\tScore: -105.9253; Policy loss: 93.50\n",
      "Episode 551, 69\tScore: -110.9488; Policy loss: 80.53\n",
      "Episode 552, 32\tScore: -102.2736; Policy loss: 99.85\n",
      "Episode 553, 58\tScore: -107.9361; Policy loss: 84.97\n",
      "Episode 554, 8\tScore: -100.0000; Policy loss: 104.39\n",
      "Episode 555, 58\tScore: -95.9812; Policy loss: 84.50\n",
      "Episode 556, 21\tScore: -102.1217; Policy loss: 100.84\n",
      "Episode 557, 28\tScore: -100.0000; Policy loss: 95.88\n",
      "Episode 558, 14\tScore: -101.0829; Policy loss: 100.44\n",
      "Episode 559, 18\tScore: -100.0000; Policy loss: 98.29\n",
      "Episode 560, 6\tScore: -102.3619; Policy loss: 104.50\n",
      "Episode 561, 30\tScore: -109.9212; Policy loss: 101.08\n",
      "Episode 562, 32\tScore: -100.7070; Policy loss: 93.45\n",
      "Episode 563, 5\tScore: -94.3652; Policy loss: 110.94\n",
      "Episode 564, 8\tScore: -104.2768; Policy loss: 101.05\n",
      "Episode 565, 9\tScore: -86.6366; Policy loss: 100.44\n",
      "Episode 566, 11\tScore: -84.9509; Policy loss: 105.02\n",
      "Episode 567, 32\tScore: -92.8571; Policy loss: 96.35\n",
      "Episode 568, 21\tScore: -100.8175; Policy loss: 95.54\n",
      "Episode 569, 9\tScore: -89.4969; Policy loss: 94.42\n",
      "Episode 570, 60\tScore: -96.5962; Policy loss: 79.11\n",
      "Episode 571, 14\tScore: -100.0000; Policy loss: 100.49\n",
      "Episode 572, 11\tScore: -104.9363; Policy loss: 108.20\n",
      "Episode 573, 7\tScore: -101.1990; Policy loss: 102.58\n",
      "Episode 574, 24\tScore: -105.6578; Policy loss: 97.66\n",
      "Episode 575, 32\tScore: -100.0000; Policy loss: 92.47\n",
      "Episode 576, 43\tScore: -101.9664; Policy loss: 86.92\n",
      "Episode 577, 29\tScore: -100.0000; Policy loss: 97.33\n",
      "Episode 578, 28\tScore: -101.9963; Policy loss: 97.82\n",
      "Episode 579, 29\tScore: -110.4744; Policy loss: 101.33\n",
      "Episode 580, 8\tScore: -100.2058; Policy loss: 99.57\n",
      "Episode 581, 11\tScore: -102.4259; Policy loss: 102.86\n",
      "Episode 582, 26\tScore: -102.1038; Policy loss: 96.31\n",
      "Episode 583, 46\tScore: -108.9125; Policy loss: 93.14\n",
      "Episode 584, 56\tScore: -110.9176; Policy loss: 87.45\n",
      "Episode 585, 27\tScore: -109.9655; Policy loss: 96.24\n",
      "Episode 586, 38\tScore: -107.9186; Policy loss: 99.61\n",
      "Episode 587, 62\tScore: -127.1742; Policy loss: 96.07\n",
      "Episode 588, 17\tScore: -101.2115; Policy loss: 107.24\n",
      "Episode 589, 41\tScore: -101.6520; Policy loss: 88.93\n",
      "Episode 590, 20\tScore: -100.3639; Policy loss: 96.15\n",
      "Episode 591, 13\tScore: -103.8238; Policy loss: 105.07\n",
      "Episode 592, 51\tScore: -72.8485; Policy loss: 81.24\n",
      "Episode 593, 24\tScore: -108.7054; Policy loss: 93.39\n",
      "Episode 594, 42\tScore: -91.7428; Policy loss: 86.12\n",
      "Episode 595, 21\tScore: -105.1974; Policy loss: 100.97\n",
      "Episode 596, 35\tScore: -99.8692; Policy loss: 88.57\n",
      "Episode 597, 8\tScore: -104.8163; Policy loss: 104.84\n",
      "Episode 598, 10\tScore: -100.0000; Policy loss: 105.76\n",
      "Episode 599, 29\tScore: -100.2795; Policy loss: 92.60\n",
      "Episode 600, 18\tScore: -100.3288; Policy loss: 104.69\n",
      "Episode 601, 6\tScore: -102.3714; Policy loss: 99.59\n",
      "Episode 602, 18\tScore: -102.6495; Policy loss: 103.13\n",
      "Episode 603, 9\tScore: -101.8352; Policy loss: 92.20\n",
      "Episode 604, 24\tScore: -108.6194; Policy loss: 96.41\n",
      "Episode 605, 6\tScore: -100.0000; Policy loss: 113.58\n",
      "Episode 606, 8\tScore: -100.0480; Policy loss: 91.58\n",
      "Episode 607, 45\tScore: -105.3834; Policy loss: 86.24\n",
      "Episode 608, 53\tScore: -124.7714; Policy loss: 96.38\n",
      "Episode 609, 12\tScore: -100.7407; Policy loss: 100.81\n",
      "Episode 610, 46\tScore: -101.7493; Policy loss: 91.30\n",
      "Episode 611, 11\tScore: -100.7275; Policy loss: 102.88\n",
      "Episode 612, 36\tScore: -108.6847; Policy loss: 98.80\n",
      "Episode 613, 7\tScore: -102.5141; Policy loss: 102.95\n",
      "Episode 614, 20\tScore: -104.1095; Policy loss: 95.47\n",
      "Episode 615, 53\tScore: -119.8137; Policy loss: 95.39\n",
      "Episode 616, 31\tScore: -101.6516; Policy loss: 98.40\n",
      "Episode 617, 5\tScore: -102.3824; Policy loss: 128.05\n",
      "Episode 618, 27\tScore: -92.0049; Policy loss: 88.72\n",
      "Episode 619, 59\tScore: -106.3485; Policy loss: 84.51\n",
      "Episode 620, 20\tScore: -100.0000; Policy loss: 95.57\n",
      "Episode 621, 22\tScore: -106.1917; Policy loss: 103.11\n",
      "Episode 622, 31\tScore: 533.5920; Policy loss: -491.29\n",
      "Episode 623, 22\tScore: -101.7974; Policy loss: 98.23\n",
      "Episode 624, 33\tScore: -101.8465; Policy loss: 96.04\n",
      "Episode 625, 33\tScore: -75.9977; Policy loss: 81.90\n",
      "Episode 626, 37\tScore: -96.4105; Policy loss: 93.02\n",
      "Episode 627, 18\tScore: -102.9756; Policy loss: 105.96\n",
      "Episode 628, 38\tScore: -111.9715; Policy loss: 101.80\n",
      "Episode 629, 29\tScore: -103.4189; Policy loss: 100.22\n",
      "Episode 630, 26\tScore: -100.6003; Policy loss: 94.44\n",
      "Episode 631, 4\tScore: -100.0000; Policy loss: 99.51\n",
      "Episode 632, 22\tScore: -110.8640; Policy loss: 108.56\n",
      "Episode 633, 57\tScore: -105.4348; Policy loss: 87.42\n",
      "Episode 634, 12\tScore: -101.2886; Policy loss: 93.85\n",
      "Episode 635, 49\tScore: -99.3211; Policy loss: 87.75\n",
      "Episode 636, 86\tScore: -121.1107; Policy loss: 81.18\n",
      "Episode 637, 67\tScore: -108.3670; Policy loss: 85.40\n",
      "Episode 638, 36\tScore: -100.3362; Policy loss: 88.98\n",
      "Episode 639, 25\tScore: -102.8087; Policy loss: 98.53\n",
      "Episode 640, 20\tScore: -101.0583; Policy loss: 94.77\n",
      "Episode 641, 49\tScore: -107.0807; Policy loss: 90.93\n",
      "Episode 642, 26\tScore: -77.8885; Policy loss: 87.40\n",
      "Episode 643, 14\tScore: -89.5380; Policy loss: 89.18\n",
      "Episode 644, 16\tScore: -96.6063; Policy loss: 97.94\n",
      "Episode 645, 42\tScore: -114.0643; Policy loss: 91.71\n",
      "Episode 646, 56\tScore: -78.3433; Policy loss: 76.05\n",
      "Episode 647, 28\tScore: -108.6910; Policy loss: 99.08\n",
      "Episode 648, 17\tScore: -108.5057; Policy loss: 98.02\n",
      "Episode 649, 30\tScore: -108.1455; Policy loss: 102.19\n",
      "Episode 650, 30\tScore: -101.1942; Policy loss: 99.74\n",
      "Episode 651, 38\tScore: -100.0487; Policy loss: 90.58\n",
      "Episode 652, 22\tScore: -105.0301; Policy loss: 101.40\n",
      "Episode 653, 36\tScore: -100.0514; Policy loss: 92.81\n",
      "Episode 654, 29\tScore: -101.9469; Policy loss: 98.10\n",
      "Episode 655, 42\tScore: -105.2960; Policy loss: 91.05\n",
      "Episode 656, 10\tScore: -100.0000; Policy loss: 101.48\n",
      "Episode 657, 48\tScore: -47.0374; Policy loss: 68.03\n",
      "Episode 658, 12\tScore: -100.0000; Policy loss: 109.30\n",
      "Episode 659, 8\tScore: -100.0000; Policy loss: 103.62\n",
      "Episode 660, 16\tScore: -100.0000; Policy loss: 102.27\n",
      "Episode 661, 26\tScore: -100.0000; Policy loss: 91.82\n",
      "Episode 662, 33\tScore: -100.0142; Policy loss: 93.86\n",
      "Episode 663, 46\tScore: 522.8180; Policy loss: -440.86\n",
      "Episode 664, 18\tScore: -100.0000; Policy loss: 91.03\n",
      "Episode 665, 41\tScore: -107.6918; Policy loss: 93.52\n",
      "Episode 666, 6\tScore: -97.5949; Policy loss: 98.46\n",
      "Episode 667, 37\tScore: -106.3436; Policy loss: 91.92\n",
      "Episode 668, 6\tScore: -100.0119; Policy loss: 101.38\n",
      "Episode 669, 31\tScore: -106.7725; Policy loss: 103.06\n",
      "Episode 670, 28\tScore: -102.5547; Policy loss: 91.94\n",
      "Episode 671, 20\tScore: -100.0000; Policy loss: 95.74\n",
      "Episode 672, 37\tScore: 537.2116; Policy loss: -478.89\n",
      "Episode 673, 21\tScore: -111.5282; Policy loss: 107.18\n",
      "Episode 674, 49\tScore: -88.2623; Policy loss: 89.64\n",
      "Episode 675, 14\tScore: -100.4155; Policy loss: 106.11\n",
      "Episode 676, 35\tScore: -108.9138; Policy loss: 95.09\n",
      "Episode 677, 45\tScore: -100.1352; Policy loss: 86.00\n",
      "Episode 678, 14\tScore: -100.4361; Policy loss: 108.44\n",
      "Episode 679, 31\tScore: -93.5459; Policy loss: 90.43\n",
      "Episode 680, 38\tScore: -105.2307; Policy loss: 97.02\n",
      "Episode 681, 11\tScore: -86.7072; Policy loss: 95.73\n",
      "Episode 682, 24\tScore: -108.2243; Policy loss: 106.30\n",
      "Episode 683, 61\tScore: -104.1908; Policy loss: 83.25\n",
      "Episode 684, 43\tScore: -110.6494; Policy loss: 98.21\n",
      "Episode 685, 8\tScore: -100.0000; Policy loss: 104.66\n",
      "Episode 686, 17\tScore: -100.8713; Policy loss: 99.52\n",
      "Episode 687, 9\tScore: -100.0000; Policy loss: 100.81\n",
      "Episode 688, 5\tScore: -100.0000; Policy loss: 101.55\n",
      "Episode 689, 38\tScore: -102.4763; Policy loss: 90.27\n",
      "Episode 690, 24\tScore: -101.9961; Policy loss: 98.43\n",
      "Episode 691, 46\tScore: -96.7952; Policy loss: 90.09\n",
      "Episode 692, 39\tScore: -108.5987; Policy loss: 96.89\n",
      "Episode 693, 51\tScore: -104.4296; Policy loss: 88.87\n",
      "Episode 694, 35\tScore: -103.6179; Policy loss: 96.02\n",
      "Episode 695, 24\tScore: -105.0033; Policy loss: 99.26\n",
      "Episode 696, 15\tScore: -98.7947; Policy loss: 108.41\n",
      "Episode 697, 25\tScore: -64.7747; Policy loss: 76.75\n",
      "Episode 698, 57\tScore: -104.2384; Policy loss: 82.39\n",
      "Episode 699, 17\tScore: -100.0989; Policy loss: 98.34\n",
      "Episode 700, 14\tScore: -99.4036; Policy loss: 96.19\n",
      "Episode 701, 37\tScore: -107.4787; Policy loss: 96.75\n",
      "Episode 702, 6\tScore: -91.2701; Policy loss: 101.93\n",
      "Episode 703, 14\tScore: -100.0000; Policy loss: 103.26\n",
      "Episode 704, 30\tScore: -106.5437; Policy loss: 101.46\n",
      "Episode 705, 7\tScore: -100.0000; Policy loss: 94.87\n",
      "Episode 706, 47\tScore: -103.0340; Policy loss: 87.46\n",
      "Episode 707, 31\tScore: -107.0941; Policy loss: 93.61\n",
      "Episode 708, 19\tScore: -100.0000; Policy loss: 96.85\n",
      "Episode 709, 26\tScore: -107.4822; Policy loss: 98.47\n",
      "Episode 710, 32\tScore: -107.6989; Policy loss: 94.86\n",
      "Episode 711, 26\tScore: -102.6723; Policy loss: 96.32\n",
      "Episode 712, 8\tScore: -96.8666; Policy loss: 109.14\n",
      "Episode 713, 14\tScore: -100.4870; Policy loss: 90.48\n",
      "Episode 714, 36\tScore: -107.0311; Policy loss: 99.93\n",
      "Episode 715, 20\tScore: -100.4819; Policy loss: 104.70\n",
      "Episode 716, 24\tScore: -91.6541; Policy loss: 105.60\n",
      "Episode 717, 7\tScore: -100.0000; Policy loss: 113.76\n",
      "Episode 718, 26\tScore: -100.0000; Policy loss: 94.86\n",
      "Episode 719, 22\tScore: -103.6047; Policy loss: 98.93\n",
      "Episode 720, 42\tScore: -100.8311; Policy loss: 91.39\n",
      "Episode 721, 74\tScore: -126.4192; Policy loss: 87.26\n",
      "Episode 722, 37\tScore: 540.3413; Policy loss: -483.41\n",
      "Episode 723, 15\tScore: -106.8572; Policy loss: 106.00\n",
      "Episode 724, 15\tScore: -107.6014; Policy loss: 103.36\n",
      "Episode 725, 15\tScore: -100.0000; Policy loss: 98.51\n",
      "Episode 726, 35\tScore: -111.7671; Policy loss: 99.70\n",
      "Episode 727, 22\tScore: -100.5641; Policy loss: 102.73\n",
      "Episode 728, 7\tScore: -91.1575; Policy loss: 99.42\n",
      "Episode 729, 52\tScore: -105.4792; Policy loss: 91.10\n",
      "Episode 730, 12\tScore: -106.9497; Policy loss: 105.25\n",
      "Episode 731, 23\tScore: -104.6339; Policy loss: 95.63\n",
      "Episode 732, 46\tScore: -109.7148; Policy loss: 92.54\n",
      "Episode 733, 39\tScore: -104.1232; Policy loss: 91.25\n",
      "Episode 734, 16\tScore: -104.2141; Policy loss: 98.53\n",
      "Episode 735, 77\tScore: -109.2971; Policy loss: 80.57\n",
      "Episode 736, 25\tScore: -104.3421; Policy loss: 97.83\n",
      "Episode 737, 38\tScore: -100.3338; Policy loss: 92.98\n",
      "Episode 738, 25\tScore: -82.2953; Policy loss: 94.56\n",
      "Episode 739, 14\tScore: -100.0000; Policy loss: 100.87\n",
      "Episode 740, 54\tScore: -112.7294; Policy loss: 90.98\n",
      "Episode 741, 18\tScore: -102.6582; Policy loss: 100.75\n",
      "Episode 742, 34\tScore: 520.9368; Policy loss: -555.52\n",
      "Episode 743, 37\tScore: -100.0000; Policy loss: 91.11\n",
      "Episode 744, 56\tScore: -108.0965; Policy loss: 88.12\n",
      "Episode 745, 51\tScore: -107.7106; Policy loss: 88.07\n",
      "Episode 746, 26\tScore: -108.8829; Policy loss: 101.66\n",
      "Episode 747, 23\tScore: -100.0000; Policy loss: 98.04\n",
      "Episode 748, 14\tScore: -105.2064; Policy loss: 117.04\n",
      "Episode 749, 53\tScore: -107.6473; Policy loss: 84.32\n",
      "Episode 750, 15\tScore: -100.0000; Policy loss: 102.55\n",
      "Episode 751, 15\tScore: -102.4985; Policy loss: 111.49\n",
      "Episode 752, 19\tScore: -102.6129; Policy loss: 102.03\n",
      "Episode 753, 27\tScore: -70.3607; Policy loss: 83.88\n",
      "Episode 754, 14\tScore: -101.3645; Policy loss: 96.94\n",
      "Episode 755, 15\tScore: -100.0000; Policy loss: 103.57\n",
      "Episode 756, 11\tScore: -97.7107; Policy loss: 95.20\n",
      "Episode 757, 18\tScore: -101.2862; Policy loss: 99.39\n",
      "Episode 758, 29\tScore: -91.2978; Policy loss: 90.40\n",
      "Episode 759, 62\tScore: -105.0863; Policy loss: 82.13\n",
      "Episode 760, 12\tScore: -99.2605; Policy loss: 106.95\n",
      "Episode 761, 15\tScore: -101.3830; Policy loss: 93.65\n",
      "Episode 762, 81\tScore: -81.2626; Policy loss: 71.60\n",
      "Episode 763, 6\tScore: -100.0000; Policy loss: 112.01\n",
      "Episode 764, 19\tScore: -108.1085; Policy loss: 103.18\n",
      "Episode 765, 19\tScore: -101.3579; Policy loss: 100.35\n",
      "Episode 766, 8\tScore: -100.0000; Policy loss: 101.33\n",
      "Episode 767, 23\tScore: -98.9431; Policy loss: 99.04\n",
      "Episode 768, 24\tScore: -100.0611; Policy loss: 96.51\n",
      "Episode 769, 17\tScore: -100.0000; Policy loss: 101.06\n",
      "Episode 770, 30\tScore: -97.4038; Policy loss: 92.55\n",
      "Episode 771, 39\tScore: -107.9451; Policy loss: 95.13\n",
      "Episode 772, 17\tScore: -100.0000; Policy loss: 102.39\n",
      "Episode 773, 53\tScore: -70.5954; Policy loss: 75.28\n",
      "Episode 774, 14\tScore: -98.9391; Policy loss: 105.27\n",
      "Episode 775, 7\tScore: -100.2623; Policy loss: 101.33\n",
      "Episode 776, 23\tScore: -97.2667; Policy loss: 91.33\n",
      "Episode 777, 100\tScore: -101.6400; Policy loss: 73.49\n",
      "Episode 778, 35\tScore: -100.1475; Policy loss: 92.34\n",
      "Episode 779, 64\tScore: -66.9238; Policy loss: 64.69\n",
      "Episode 780, 6\tScore: -100.0000; Policy loss: 101.37\n",
      "Episode 781, 49\tScore: -116.2541; Policy loss: 88.27\n",
      "Episode 782, 29\tScore: -102.1058; Policy loss: 95.61\n",
      "Episode 783, 45\tScore: -100.0226; Policy loss: 88.73\n",
      "Episode 784, 16\tScore: -105.1483; Policy loss: 101.96\n",
      "Episode 785, 24\tScore: -102.7531; Policy loss: 91.07\n",
      "Episode 786, 22\tScore: -97.7739; Policy loss: 97.69\n",
      "Episode 787, 17\tScore: -103.9055; Policy loss: 98.32\n",
      "Episode 788, 8\tScore: -99.9583; Policy loss: 100.32\n",
      "Episode 789, 35\tScore: -109.7764; Policy loss: 96.90\n",
      "Episode 790, 32\tScore: -106.1896; Policy loss: 96.43\n",
      "Episode 791, 23\tScore: -104.9944; Policy loss: 106.16\n",
      "Episode 792, 51\tScore: -109.6332; Policy loss: 92.33\n",
      "Episode 793, 16\tScore: -75.9975; Policy loss: 91.83\n",
      "Episode 794, 24\tScore: -67.8961; Policy loss: 87.61\n",
      "Episode 795, 26\tScore: -100.0000; Policy loss: 93.09\n",
      "Episode 796, 6\tScore: -100.0000; Policy loss: 97.99\n",
      "Episode 797, 17\tScore: -100.0000; Policy loss: 106.16\n",
      "Episode 798, 8\tScore: -100.0000; Policy loss: 101.86\n",
      "Episode 799, 28\tScore: -100.0661; Policy loss: 94.65\n",
      "Episode 800, 27\tScore: -109.2768; Policy loss: 99.51\n",
      "Episode 801, 13\tScore: -96.2464; Policy loss: 90.10\n",
      "Episode 802, 51\tScore: -90.2356; Policy loss: 88.20\n",
      "Episode 803, 15\tScore: -101.6276; Policy loss: 105.49\n",
      "Episode 804, 29\tScore: -108.9707; Policy loss: 96.69\n",
      "Episode 805, 23\tScore: -103.2619; Policy loss: 96.99\n",
      "Episode 806, 7\tScore: -100.0874; Policy loss: 105.38\n",
      "Episode 807, 14\tScore: -97.3734; Policy loss: 99.64\n",
      "Episode 808, 17\tScore: -99.5578; Policy loss: 94.86\n",
      "Episode 809, 23\tScore: -105.4910; Policy loss: 98.29\n",
      "Episode 810, 46\tScore: -83.1612; Policy loss: 81.90\n",
      "Episode 811, 13\tScore: -100.4585; Policy loss: 104.07\n",
      "Episode 812, 8\tScore: -96.4229; Policy loss: 100.92\n",
      "Episode 813, 25\tScore: -104.4338; Policy loss: 100.15\n",
      "Episode 814, 10\tScore: -103.6539; Policy loss: 90.71\n",
      "Episode 815, 32\tScore: -98.7468; Policy loss: 90.53\n",
      "Episode 816, 32\tScore: -105.3110; Policy loss: 94.01\n",
      "Episode 817, 32\tScore: -109.3103; Policy loss: 104.62\n",
      "Episode 818, 52\tScore: -59.9128; Policy loss: 71.20\n",
      "Episode 819, 12\tScore: -103.3582; Policy loss: 116.24\n",
      "Episode 820, 29\tScore: -107.4250; Policy loss: 103.83\n",
      "Episode 821, 41\tScore: -111.6626; Policy loss: 99.06\n",
      "Episode 822, 12\tScore: -103.2887; Policy loss: 109.76\n",
      "Episode 823, 22\tScore: -107.9907; Policy loss: 105.13\n",
      "Episode 824, 40\tScore: -106.7466; Policy loss: 94.28\n",
      "Episode 825, 10\tScore: -100.0000; Policy loss: 99.92\n",
      "Episode 826, 64\tScore: -86.6528; Policy loss: 81.69\n",
      "Episode 827, 14\tScore: -100.0000; Policy loss: 103.19\n",
      "Episode 828, 43\tScore: -107.2193; Policy loss: 92.04\n",
      "Episode 829, 8\tScore: -100.0000; Policy loss: 119.54\n",
      "Episode 830, 10\tScore: -100.9449; Policy loss: 112.21\n",
      "Episode 831, 12\tScore: -106.3225; Policy loss: 106.00\n",
      "Episode 832, 28\tScore: -108.7244; Policy loss: 96.15\n",
      "Episode 833, 16\tScore: -100.4928; Policy loss: 103.12\n",
      "Episode 834, 41\tScore: -101.1447; Policy loss: 88.77\n",
      "Episode 835, 13\tScore: -100.1804; Policy loss: 109.81\n",
      "Episode 836, 10\tScore: -103.1535; Policy loss: 102.99\n",
      "Episode 837, 32\tScore: -103.1164; Policy loss: 92.79\n",
      "Episode 838, 48\tScore: -100.6515; Policy loss: 93.38\n",
      "Episode 839, 48\tScore: -126.0254; Policy loss: 95.98\n",
      "Episode 840, 13\tScore: -93.1576; Policy loss: 104.60\n",
      "Episode 841, 20\tScore: -100.3545; Policy loss: 98.78\n",
      "Episode 842, 17\tScore: -81.3082; Policy loss: 89.54\n",
      "Episode 843, 24\tScore: -101.5418; Policy loss: 100.33\n",
      "Episode 844, 6\tScore: -100.0000; Policy loss: 107.16\n",
      "Episode 845, 16\tScore: -100.1647; Policy loss: 100.30\n",
      "Episode 846, 34\tScore: -105.1168; Policy loss: 96.06\n",
      "Episode 847, 42\tScore: -110.0438; Policy loss: 95.58\n",
      "Episode 848, 41\tScore: 546.0753; Policy loss: -477.71\n",
      "Episode 849, 11\tScore: -100.0000; Policy loss: 100.38\n",
      "Episode 850, 42\tScore: -84.6270; Policy loss: 89.48\n",
      "Episode 851, 18\tScore: -101.0347; Policy loss: 99.40\n",
      "Episode 852, 16\tScore: -100.0000; Policy loss: 102.27\n",
      "Episode 853, 15\tScore: -80.0087; Policy loss: 86.67\n",
      "Episode 854, 28\tScore: -97.2737; Policy loss: 93.11\n",
      "Episode 855, 41\tScore: -104.3452; Policy loss: 90.11\n",
      "Episode 856, 32\tScore: -103.3630; Policy loss: 96.26\n",
      "Episode 857, 48\tScore: -105.1036; Policy loss: 91.79\n",
      "Episode 858, 51\tScore: -88.8896; Policy loss: 82.25\n",
      "Episode 859, 33\tScore: -107.8155; Policy loss: 95.17\n",
      "Episode 860, 24\tScore: -102.3644; Policy loss: 94.01\n",
      "Episode 861, 24\tScore: -99.9548; Policy loss: 96.77\n",
      "Episode 862, 7\tScore: -100.3942; Policy loss: 99.17\n",
      "Episode 863, 6\tScore: -100.9659; Policy loss: 115.16\n",
      "Episode 864, 51\tScore: -106.5464; Policy loss: 87.01\n",
      "Episode 865, 19\tScore: -100.5548; Policy loss: 97.77\n",
      "Episode 866, 16\tScore: -101.2408; Policy loss: 100.67\n",
      "Episode 867, 17\tScore: -104.8899; Policy loss: 105.50\n",
      "Episode 868, 17\tScore: -91.7040; Policy loss: 99.31\n",
      "Episode 869, 7\tScore: -102.6635; Policy loss: 106.66\n",
      "Episode 870, 29\tScore: -101.1148; Policy loss: 95.13\n",
      "Episode 871, 26\tScore: -85.2775; Policy loss: 88.01\n",
      "Episode 872, 17\tScore: -100.0000; Policy loss: 100.73\n",
      "Episode 873, 31\tScore: -92.3688; Policy loss: 93.41\n",
      "Episode 874, 11\tScore: -100.5833; Policy loss: 107.28\n",
      "Episode 875, 30\tScore: -103.7345; Policy loss: 92.18\n",
      "Episode 876, 30\tScore: -108.3867; Policy loss: 99.08\n",
      "Episode 877, 12\tScore: -100.0000; Policy loss: 103.36\n",
      "Episode 878, 30\tScore: -113.9458; Policy loss: 103.45\n",
      "Episode 879, 9\tScore: -103.3695; Policy loss: 99.53\n",
      "Episode 880, 11\tScore: -103.1254; Policy loss: 105.80\n",
      "Episode 881, 20\tScore: -103.5969; Policy loss: 100.82\n",
      "Episode 882, 48\tScore: -90.3006; Policy loss: 87.95\n",
      "Episode 883, 13\tScore: -92.4369; Policy loss: 99.14\n",
      "Episode 884, 22\tScore: -105.7807; Policy loss: 98.27\n",
      "Episode 885, 8\tScore: -91.7281; Policy loss: 87.06\n",
      "Episode 886, 16\tScore: -101.7281; Policy loss: 89.44\n",
      "Episode 887, 70\tScore: -107.9598; Policy loss: 85.26\n",
      "Episode 888, 26\tScore: -103.3811; Policy loss: 89.86\n",
      "Episode 889, 27\tScore: -105.3928; Policy loss: 98.34\n",
      "Episode 890, 39\tScore: -102.9158; Policy loss: 88.99\n",
      "Episode 891, 32\tScore: -109.9007; Policy loss: 94.10\n",
      "Episode 892, 15\tScore: -86.4043; Policy loss: 87.66\n",
      "Episode 893, 15\tScore: -100.0000; Policy loss: 101.36\n",
      "Episode 894, 35\tScore: 526.9470; Policy loss: -461.05\n",
      "Episode 895, 32\tScore: -105.2155; Policy loss: 95.92\n",
      "Episode 896, 24\tScore: -100.6561; Policy loss: 95.69\n",
      "Episode 897, 9\tScore: -100.0000; Policy loss: 108.55\n",
      "Episode 898, 45\tScore: -101.7669; Policy loss: 87.72\n",
      "Episode 899, 10\tScore: -92.3137; Policy loss: 108.79\n",
      "Episode 900, 25\tScore: -103.1924; Policy loss: 95.63\n",
      "Episode 901, 26\tScore: 531.4855; Policy loss: -524.22\n",
      "Episode 902, 26\tScore: -103.7242; Policy loss: 97.85\n",
      "Episode 903, 47\tScore: -112.4260; Policy loss: 95.41\n",
      "Episode 904, 62\tScore: -74.6592; Policy loss: 79.25\n",
      "Episode 905, 14\tScore: -100.0000; Policy loss: 100.62\n",
      "Episode 906, 14\tScore: -103.5049; Policy loss: 104.32\n",
      "Episode 907, 41\tScore: -94.9105; Policy loss: 84.07\n",
      "Episode 908, 57\tScore: -98.1011; Policy loss: 89.59\n",
      "Episode 909, 54\tScore: -83.1337; Policy loss: 83.77\n",
      "Episode 910, 24\tScore: -108.8391; Policy loss: 103.62\n",
      "Episode 911, 24\tScore: -103.4108; Policy loss: 96.00\n",
      "Episode 912, 12\tScore: -100.0000; Policy loss: 104.44\n",
      "Episode 913, 34\tScore: -104.7958; Policy loss: 96.75\n",
      "Episode 914, 13\tScore: -98.3822; Policy loss: 92.99\n",
      "Episode 915, 54\tScore: -119.2734; Policy loss: 90.82\n",
      "Episode 916, 39\tScore: -113.8568; Policy loss: 95.08\n",
      "Episode 917, 14\tScore: -102.1397; Policy loss: 98.90\n",
      "Episode 918, 8\tScore: -100.0000; Policy loss: 100.53\n",
      "Episode 919, 29\tScore: 517.9402; Policy loss: -542.53\n",
      "Episode 920, 23\tScore: -103.7315; Policy loss: 95.72\n",
      "Episode 921, 17\tScore: -106.4602; Policy loss: 103.24\n",
      "Episode 922, 34\tScore: -97.7906; Policy loss: 89.65\n",
      "Episode 923, 6\tScore: -100.7376; Policy loss: 114.84\n",
      "Episode 924, 25\tScore: -106.6379; Policy loss: 99.22\n",
      "Episode 925, 24\tScore: -100.0458; Policy loss: 98.32\n",
      "Episode 926, 15\tScore: -100.0000; Policy loss: 102.89\n",
      "Episode 927, 17\tScore: -100.0000; Policy loss: 98.03\n",
      "Episode 928, 36\tScore: -99.1162; Policy loss: 91.86\n",
      "Episode 929, 13\tScore: -103.7939; Policy loss: 100.83\n",
      "Episode 930, 23\tScore: -105.1086; Policy loss: 102.75\n",
      "Episode 931, 40\tScore: -100.0000; Policy loss: 91.62\n",
      "Episode 932, 40\tScore: -90.4580; Policy loss: 88.53\n",
      "Episode 933, 12\tScore: -100.0000; Policy loss: 99.55\n",
      "Episode 934, 16\tScore: -100.9050; Policy loss: 93.22\n",
      "Episode 935, 11\tScore: -99.1072; Policy loss: 130.92\n",
      "Episode 936, 24\tScore: -100.1600; Policy loss: 102.94\n",
      "Episode 937, 26\tScore: -100.7230; Policy loss: 100.42\n",
      "Episode 938, 20\tScore: -97.4699; Policy loss: 104.38\n",
      "Episode 939, 17\tScore: -103.3786; Policy loss: 97.21\n",
      "Episode 940, 17\tScore: -88.5306; Policy loss: 77.56\n",
      "Episode 941, 76\tScore: -87.5978; Policy loss: 75.75\n",
      "Episode 942, 38\tScore: -101.1624; Policy loss: 91.30\n",
      "Episode 943, 20\tScore: -100.3056; Policy loss: 100.61\n",
      "Episode 944, 7\tScore: -100.0000; Policy loss: 100.09\n",
      "Episode 945, 20\tScore: -100.9919; Policy loss: 100.74\n",
      "Episode 946, 16\tScore: -102.6295; Policy loss: 100.96\n",
      "Episode 947, 10\tScore: -103.3328; Policy loss: 106.03\n",
      "Episode 948, 19\tScore: -92.7528; Policy loss: 94.53\n",
      "Episode 949, 10\tScore: -102.4355; Policy loss: 100.10\n",
      "Episode 950, 40\tScore: -111.7321; Policy loss: 100.29\n",
      "Episode 951, 28\tScore: -109.5165; Policy loss: 104.07\n",
      "Episode 952, 75\tScore: -113.9904; Policy loss: 85.96\n",
      "Episode 953, 37\tScore: -104.4165; Policy loss: 92.20\n",
      "Episode 954, 23\tScore: -100.0988; Policy loss: 95.11\n",
      "Episode 955, 19\tScore: -100.4377; Policy loss: 98.16\n",
      "Episode 956, 31\tScore: -104.9442; Policy loss: 100.54\n",
      "Episode 957, 33\tScore: -101.7408; Policy loss: 96.39\n",
      "Episode 958, 20\tScore: -105.1552; Policy loss: 110.20\n",
      "Episode 959, 20\tScore: -88.3504; Policy loss: 96.87\n",
      "Episode 960, 22\tScore: -99.6088; Policy loss: 100.49\n",
      "Episode 961, 22\tScore: -103.3252; Policy loss: 92.97\n",
      "Episode 962, 37\tScore: -105.1959; Policy loss: 89.87\n",
      "Episode 963, 18\tScore: -100.0000; Policy loss: 95.24\n",
      "Episode 964, 13\tScore: -100.1196; Policy loss: 97.21\n",
      "Episode 965, 34\tScore: -94.1554; Policy loss: 94.11\n",
      "Episode 966, 23\tScore: -74.6869; Policy loss: 83.51\n",
      "Episode 967, 32\tScore: -82.5908; Policy loss: 80.93\n",
      "Episode 968, 32\tScore: -103.3108; Policy loss: 94.44\n",
      "Episode 969, 26\tScore: -110.8337; Policy loss: 105.07\n",
      "Episode 970, 12\tScore: -105.3093; Policy loss: 106.21\n",
      "Episode 971, 4\tScore: -100.0000; Policy loss: 110.24\n",
      "Episode 972, 26\tScore: -113.5736; Policy loss: 112.85\n",
      "Episode 973, 38\tScore: -73.0991; Policy loss: 82.45\n",
      "Episode 974, 14\tScore: -100.9317; Policy loss: 96.10\n",
      "Episode 975, 60\tScore: -111.5504; Policy loss: 91.34\n",
      "Episode 976, 11\tScore: -104.4352; Policy loss: 112.72\n",
      "Episode 977, 21\tScore: -103.4475; Policy loss: 95.23\n",
      "Episode 978, 30\tScore: -100.8645; Policy loss: 93.45\n",
      "Episode 979, 12\tScore: -100.1274; Policy loss: 98.52\n",
      "Episode 980, 44\tScore: -119.9995; Policy loss: 100.53\n",
      "Episode 981, 49\tScore: -118.6195; Policy loss: 95.79\n",
      "Episode 982, 17\tScore: -100.5214; Policy loss: 102.07\n",
      "Episode 983, 42\tScore: -98.3457; Policy loss: 89.83\n",
      "Episode 984, 45\tScore: -114.3127; Policy loss: 94.40\n",
      "Episode 985, 38\tScore: -106.7677; Policy loss: 94.16\n",
      "Episode 986, 32\tScore: -100.8547; Policy loss: 93.20\n",
      "Episode 987, 52\tScore: -100.8512; Policy loss: 88.79\n",
      "Episode 988, 18\tScore: -105.0514; Policy loss: 108.44\n",
      "Episode 989, 37\tScore: -95.1870; Policy loss: 94.39\n",
      "Episode 990, 41\tScore: -101.2201; Policy loss: 89.01\n",
      "Episode 991, 30\tScore: -93.1400; Policy loss: 92.99\n",
      "Episode 992, 29\tScore: -106.5816; Policy loss: 99.16\n",
      "Episode 993, 38\tScore: -101.3882; Policy loss: 90.35\n",
      "Episode 994, 29\tScore: -100.0000; Policy loss: 96.07\n",
      "Episode 995, 77\tScore: -114.9018; Policy loss: 81.21\n",
      "Episode 996, 9\tScore: -103.1825; Policy loss: 111.94\n",
      "Episode 997, 22\tScore: -101.1466; Policy loss: 97.41\n",
      "Episode 998, 62\tScore: -102.8526; Policy loss: 82.16\n",
      "Episode 999, 18\tScore: -100.0695; Policy loss: 99.75\n",
      "Episode 1000, 25\tScore: -102.4088; Policy loss: 92.44\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>policy_loss</td><td></td></tr><tr><td>score</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>policy_loss</td><td>92.43647</td></tr><tr><td>score</td><td>-102.40881</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fragrant-shape-6</strong> at: <a href='https://wandb.ai/giovancombo/navigation-goal/runs/2u89ox6l' target=\"_blank\">https://wandb.ai/giovancombo/navigation-goal/runs/2u89ox6l</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240131_012840-2u89ox6l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(env_name, render_mode='human') \n",
    "policy = PolicyNet(env, hidden_size).to(device)\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=lr)\n",
    "\n",
    "with wandb.init(project=\"navigation-goal\"):\n",
    "    policy.train()\n",
    "    for episode in range(episodes):\n",
    "        (state, info) = env.reset()\n",
    "        terminated, truncated = False, False\n",
    "        states, actions, log_probs, rewards = [], [], [], []\n",
    "        score = 0\n",
    "\n",
    "        while True:\n",
    "            env.render()\n",
    "            state = torch.tensor(state, dtype = torch.float32, device = device)\n",
    "            action_logits = policy(state)                               # Logits = Tensor of shape 3 (3 actions)\n",
    "            action = torch.multinomial(action_logits.exp(), 1).item()   # Sample an action from the policy\n",
    "            log_logits = torch.log(action_logits)                       # Log probability of each action\n",
    "\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            log_probs.append(log_logits[action])\n",
    "\n",
    "            state, reward, terminated, truncated, info = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            score += reward\n",
    "                \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # Compute the discounted rewards\n",
    "        policy_loss = torch.tensor(0, dtype=torch.float32, device = device)\n",
    "        for t in range(len(rewards)):\n",
    "            gammas = gamma ** np.arange(len(rewards) - t)\n",
    "            G = torch.tensor(np.sum(np.array(rewards[t:]) * gammas), dtype=torch.float32, device = device)\n",
    "            policy_loss += log_probs[t] * G\n",
    "\n",
    "        policy_loss /= len(rewards)\n",
    "        #print(policy_loss)\n",
    "        policy_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Episode {episode+1}, {len(rewards)}\\tScore: {score:.4f}; Policy loss: {policy_loss:.2f}')\n",
    "\n",
    "        wandb.log({\"score\": score, \"policy_loss\": policy_loss}, step=episode)\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad32251",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Solving another environment\n",
    "\n",
    "The [Gymnasium](https://gymnasium.farama.org/) framework has a ton of interesting and fun environments to work with. Pick one and try to solve it using any technique you like. The [Lunar Lander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) environment is a fun one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6c801",
   "metadata": {},
   "source": [
    "Ok, so, let's build a new LunarLander environment, with render mode so that we can graphically see progress of our lander."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b45c9d",
   "metadata": {},
   "source": [
    "To set things, I start implementing a lander that takes totally random actions at each time tick. The total reward will be very bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75049b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reinforce import *\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "env_name = \"LunarLander-v2\"\n",
    "episodes = 20\n",
    "\n",
    "env = gym.make(env_name, render_mode='human', gravity=0.0,\n",
    "                                              enable_wind=False,\n",
    "                                              wind_power=0.0,\n",
    "                                              turbulence_power=0.0,)\n",
    "\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    score = 0\n",
    "\n",
    "    while True:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()              # Scelta random tra i valori [0,1,2,3] delle azioni\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    print(f'Episode {episode},  score: {score:.4f}')\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9997e40f",
   "metadata": {},
   "source": [
    "...As expected. Now I will try to use the REINFORCE algorithm already implemented in Francesco's work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54251a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a policy network.\n",
    "policy = PolicyNet(env).to(device)\n",
    "\n",
    "# Train the agent.\n",
    "running  = reinforce(policy, env, env_render, device=device, lr=1e-4, num_episodes=1000)\n",
    "running += reinforce(policy, env, env_render, device=device, lr=1e-5, num_episodes=1000)\n",
    "plt.plot(running)\n",
    "\n",
    "# Close up everything\n",
    "env_render.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305bfa42",
   "metadata": {},
   "source": [
    "...And finally, with my own implementation of REINFORCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a75692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a policy network.\n",
    "policy = PolicyNet(env).to(device)\n",
    "\n",
    "# Train the agent.\n",
    "running  = reinforce(policy, env, env_render, device=device, lr=1e-4, num_episodes=1000)\n",
    "running += reinforce(policy, env, env_render, device=device, lr=1e-5, num_episodes=1000)\n",
    "plt.plot(running)\n",
    "\n",
    "# Close up everything\n",
    "env_render.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf1447-d222-4b24-a357-5b7f9824390c",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Advanced techniques \n",
    "\n",
    "The `REINFORCE` and Q-Learning approaches, though venerable, are not even close to the state-of-the-art. Try using an off-the-shelf implementation of [Proximal Policy Optimization (PPO)](https://arxiv.org/abs/1707.06347) to solve one (or more) of these environments. Compare your results with those of Q-Learning and/or REINFORCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b8a52-d97b-4c32-bfcb-9069e7527ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
